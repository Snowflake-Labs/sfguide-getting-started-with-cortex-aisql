{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Features: Cortex Guard and Helper Functions\n",
        "\n",
        "This notebook demonstrates:\n",
        "- **Cortex Guard**: Safety filtering for AI responses\n",
        "- **AI_COUNT_TOKENS**: Token counting for optimization\n",
        "- **PROMPT**: Dynamic prompt building\n",
        "- **TRY_COMPLETE**: Error-safe completions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "\n",
        "session = get_active_session()\n",
        "session.sql(\"USE DATABASE AISQL_DB\").collect()\n",
        "session.sql(\"USE SCHEMA AISQL_SCHEMA\").collect()\n",
        "session.sql(\"USE WAREHOUSE AISQL_WH\").collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cortex Guard: Safety Filtering\n",
        "\n",
        "Filter potentially unsafe AI responses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate responses with Cortex Guard\n",
        "sql = \"\"\"\n",
        "SELECT \n",
        "    ticket_id,\n",
        "    SUBSTR(content, 1, 100) as customer_message,\n",
        "    AI_COMPLETE('llama3.1-8b', \n",
        "        'Generate a professional response to: ' || content,\n",
        "        {'guard_enable': true}) as safe_response,\n",
        "    CASE \n",
        "        WHEN AI_COMPLETE('llama3.1-8b', \n",
        "            'Generate a professional response to: ' || content,\n",
        "            {'guard_enable': true}) IS NULL \n",
        "        THEN 'Filtered'\n",
        "        ELSE 'Approved'\n",
        "    END as guard_status\n",
        "FROM emails\n",
        "LIMIT 20\n",
        "\"\"\"\n",
        "\n",
        "df_guard = session.sql(sql).to_pandas()\n",
        "st.subheader(\"Cortex Guard Results\")\n",
        "st.dataframe(df_guard)\n",
        "\n",
        "# Show guard statistics\n",
        "guard_stats = df_guard['GUARD_STATUS'].value_counts()\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    st.metric(\"Approved\", guard_stats.get('Approved', 0))\n",
        "with col2:\n",
        "    st.metric(\"Filtered\", guard_stats.get('Filtered', 0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. AI_COUNT_TOKENS: Token Management\n",
        "\n",
        "Count tokens for cost optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count tokens for cost estimation\n",
        "sql = \"\"\"\n",
        "SELECT \n",
        "    ticket_id,\n",
        "    SUBSTR(content, 1, 100) as content_preview,\n",
        "    LENGTH(content) as char_count,\n",
        "    AI_COUNT_TOKENS('claude-3-7-sonnet', content) as token_count,\n",
        "    ROUND((AI_COUNT_TOKENS('claude-3-7-sonnet', content) / 1000.0) * 0.003, 6) as estimated_cost_usd\n",
        "FROM emails\n",
        "ORDER BY token_count DESC\n",
        "LIMIT 20\n",
        "\"\"\"\n",
        "\n",
        "df_tokens = session.sql(sql).to_pandas()\n",
        "st.subheader(\"Token Analysis\")\n",
        "st.dataframe(df_tokens)\n",
        "\n",
        "# Token distribution\n",
        "hist = alt.Chart(df_tokens).mark_bar().encode(\n",
        "    alt.X('TOKEN_COUNT:Q', bin=alt.Bin(maxbins=20)),\n",
        "    y='count()'\n",
        ").properties(height=300)\n",
        "st.subheader(\"Token Count Distribution\")\n",
        "st.altair_chart(hist, use_container_width=True)\n",
        "\n",
        "# Cost summary\n",
        "total_tokens = df_tokens['TOKEN_COUNT'].sum()\n",
        "total_cost = df_tokens['ESTIMATED_COST_USD'].sum()\n",
        "st.metric(\"Total Tokens\", f\"{total_tokens:,}\")\n",
        "st.metric(\"Estimated Cost\", f\"${total_cost:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. PROMPT Function: Dynamic Prompts\n",
        "\n",
        "Build dynamic prompts with parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use PROMPT for dynamic prompt building\n",
        "sql = \"\"\"\n",
        "SELECT \n",
        "    ticket_id,\n",
        "    user_id,\n",
        "    SUBSTR(content, 1, 100) as content_preview,\n",
        "    AI_COMPLETE('claude-3-7-sonnet',\n",
        "        PROMPT('User {0} submitted ticket {1}. Please provide a helpful response to: {2}',\n",
        "               user_id, ticket_id, content)) as personalized_response\n",
        "FROM emails\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "df_prompt = session.sql(sql).to_pandas()\n",
        "st.subheader(\"Dynamic Prompt Results\")\n",
        "st.dataframe(df_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook covered advanced Cortex AISQL features:\n",
        "- **Cortex Guard** for safe AI responses\n",
        "- **AI_COUNT_TOKENS** for cost optimization\n",
        "- **PROMPT** for dynamic prompt construction\n",
        "- **TRY_COMPLETE** for error handling\n",
        "\n",
        "These functions help build production-ready AI applications with proper safety, cost management, and error handling.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
