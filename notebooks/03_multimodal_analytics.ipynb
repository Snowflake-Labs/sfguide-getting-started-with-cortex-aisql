{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multimodal Analytics with Cortex AISQL\n",
        "\n",
        "This notebook demonstrates:\n",
        "- **AI_COMPLETE** with images\n",
        "- **AI_TRANSCRIBE** for audio files\n",
        "- **AI_PARSE_DOCUMENT** for OCR\n",
        "- **TO_FILE** for file references\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "\n",
        "session = get_active_session()\n",
        "session.sql(\"USE DATABASE AISQL_DB\").collect()\n",
        "session.sql(\"USE SCHEMA AISQL_SCHEMA\").collect()\n",
        "session.sql(\"USE WAREHOUSE AISQL_WH\").collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. AI_COMPLETE with Images\n",
        "\n",
        "Analyze screenshots and images using vision models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze images with AI_COMPLETE\n",
        "sql = \"\"\"\n",
        "SELECT \n",
        "    relative_path,\n",
        "    AI_COMPLETE('pixtral-large', \n",
        "        'Describe this image and identify any issues or errors visible.', \n",
        "        img_file) as image_analysis\n",
        "FROM images\n",
        "WHERE relative_path LIKE 'screenshot%'\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "df_images = session.sql(sql).to_pandas()\n",
        "st.subheader(\"Image Analysis Results\")\n",
        "st.dataframe(df_images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. AI_TRANSCRIBE for Audio\n",
        "\n",
        "Transcribe voicemail audio files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transcribe audio files\n",
        "sql = \"\"\"\n",
        "SELECT \n",
        "    relative_path,\n",
        "    AI_TRANSCRIBE(audio_file)['text'] as transcription,\n",
        "    AI_SENTIMENT(AI_TRANSCRIBE(audio_file)['text']) as sentiment_score\n",
        "FROM voicemails\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "df_audio = session.sql(sql).to_pandas()\n",
        "st.subheader(\"Audio Transcriptions\")\n",
        "st.dataframe(df_audio)\n",
        "\n",
        "# Sentiment distribution\n",
        "if len(df_audio) > 0:\n",
        "    avg_sentiment = df_audio['SENTIMENT_SCORE'].mean()\n",
        "    st.metric(\"Average Voicemail Sentiment\", f\"{avg_sentiment:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. AI_PARSE_DOCUMENT for OCR\n",
        "\n",
        "Extract text from images using OCR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse documents with OCR\n",
        "sql = \"\"\"\n",
        "SELECT \n",
        "    relative_path,\n",
        "    AI_PARSE_DOCUMENT(img_file, {'mode': 'OCR'}) as extracted_text,\n",
        "    LENGTH(AI_PARSE_DOCUMENT(img_file, {'mode': 'OCR'})) as text_length\n",
        "FROM images\n",
        "WHERE relative_path LIKE 'screenshot%'\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "df_ocr = session.sql(sql).to_pandas()\n",
        "st.subheader(\"OCR Extracted Text\")\n",
        "\n",
        "for idx, row in df_ocr.iterrows():\n",
        "    with st.expander(f\"{row['RELATIVE_PATH']} ({row['TEXT_LENGTH']} chars)\"):\n",
        "        st.write(row['EXTRACTED_TEXT'])\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
